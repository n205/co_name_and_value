import logging
import requests
import numpy as np
from io import BytesIO
from pypdf import PdfReader
from pdf2image import convert_from_bytes
import warnings
from gspread_dataframe import get_as_dataframe
import google.generativeai as genai
import os


# -------------------------------
# Gemini åˆæœŸåŒ–ï¼ˆå…±é€šï¼‰
# -------------------------------
def init_gemini():
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise RuntimeError("ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    genai.configure(api_key=api_key)
    return genai.GenerativeModel("gemini-2.0-flash")


text_model = None
image_model = None


# ============================================================
#  1) ãƒãƒªãƒ¥ãƒ¼ï¼ˆãƒ†ã‚­ã‚¹ãƒˆç‰ˆï¼‰æŠ½å‡º
# ============================================================
def extract_value_from_text(pdf_bytes):
    global text_model
    if text_model is None:
        text_model = init_gemini()

    try:
        reader = PdfReader(BytesIO(pdf_bytes))
        all_text = ""

        for i in range(min(10, len(reader.pages))):
            text = reader.pages[i].extract_text()
            if text:
                all_text += text + "\n"

        if not all_text.strip():
            return "å–å¾—å¤±æ•—"

        prompt = """
        ä»¥ä¸‹ã¯ä¼æ¥­ã®çµ±åˆå ±å‘Šæ›¸ã§ã™ã€‚
        ã“ã®ä¸­ã‹ã‚‰ä¼æ¥­ãŒæç¤ºã—ã¦ã„ã‚‹ã€Œãƒãƒªãƒ¥ãƒ¼ã€ã€Œè¡Œå‹•æŒ‡é‡ã€ã€Œä¾¡å€¤è¦³ã€ã€Œè¡Œå‹•è¦ç¯„ã€ã«è©²å½“ã™ã‚‹å†…å®¹ã‚’150æ–‡å­—ä»¥å†…ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚

        ãƒ»ç¤¾å“¡ãŒã©ã®ã‚ˆã†ãªè¡Œå‹•ã‚„å§¿å‹¢ã‚’æ±‚ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã‹ã‚’å„ªå…ˆ
        ãƒ»èª¬æ˜æ–‡ã€å‰ç½®ãã€ãƒ©ãƒ™ãƒ«ã¯ç¦æ­¢
        ãƒ»å†…å®¹ãã®ã‚‚ã®ã ã‘ã‚’è¿”ã™
        ãƒ»å–å¾—ã§ããªã„å ´åˆã¯ã€Œå–å¾—å¤±æ•—ã€
        """

        response = text_model.generate_content([prompt, all_text])
        result = response.text.strip()

        return result if result else "å–å¾—å¤±æ•—"

    except Exception as e:
        warnings.warn(f"Geminiãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†å¤±æ•—: {e}")
        return "å–å¾—å¤±æ•—"


# ============================================================
#  update_ãƒãƒªãƒ¥ãƒ¼Tï¼ˆãƒ†ã‚­ã‚¹ãƒˆï¼‰
# ============================================================
def update_ãƒãƒªãƒ¥ãƒ¼T(worksheet):
    logging.info("ğŸ§­ update_ãƒãƒªãƒ¥ãƒ¼T é–‹å§‹")

    df = get_as_dataframe(worksheet)
    df.fillna('', inplace=True)

    if 'ãƒãƒªãƒ¥ãƒ¼T' not in df.columns:
        df['ãƒãƒªãƒ¥ãƒ¼T'] = ''

    update_count = 0

    for idx, row in df.iterrows():
        url = row.get("URL", "")
        val_t = row.get("ãƒãƒªãƒ¥ãƒ¼T", "")
        company = row.get("ä¼šç¤¾å", "")

        if not url or val_t:
            continue

        if company in ["å¯¾è±¡å¤–", "å–å¾—å¤±æ•—", ""]:
            df.at[idx, "ãƒãƒªãƒ¥ãƒ¼T"] = "å¯¾è±¡å¤–"
            update_count += 1
            logging.info(f"â­ï¸ å¯¾è±¡å¤–ï¼ˆä¼šç¤¾åï¼‰: {url}")
            continue

        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            res = requests.get(url, headers=headers, timeout=20)

            if res.status_code == 200:
                extracted = extract_value_from_text(res.content)
                df.at[idx, "ãƒãƒªãƒ¥ãƒ¼T"] = extracted
                update_count += 1
                logging.info(f"ğŸ“ æŠ½å‡º(T): {url} â†’ {extracted}")

            else:
                df.at[idx, "ãƒãƒªãƒ¥ãƒ¼T"] = "å–å¾—å¤±æ•—"
                update_count += 1
                logging.warning(f"âš ï¸ DLå¤±æ•— {res.status_code}: {url}")

        except Exception as e:
            df.at[idx, "ãƒãƒªãƒ¥ãƒ¼T"] = "å–å¾—å¤±æ•—"
            update_count += 1
            logging.warning(f"âŒ ä¾‹å¤–ç™ºç”Ÿ {e}: {url}")

    df.replace([np.nan, np.inf, -np.inf], '', inplace=True)

    # Excel åˆ—åå¤‰æ›
    def col_to_letter(index):
        letters = ""
        while index >= 0:
            index, rem = divmod(index, 26)
            letters = chr(65 + rem) + letters
            index -= 1
        return letters

    col_index = df.columns.get_loc("ãƒãƒªãƒ¥ãƒ¼T")
    col_letter = col_to_letter(col_index)

    worksheet.update(
        f"{col_letter}2:{col_letter}{len(df)+1}",
        [[v] for v in df["ãƒãƒªãƒ¥ãƒ¼T"].tolist()]
    )

    logging.info(f"ğŸ“ {update_count} ä»¶ã®ãƒãƒªãƒ¥ãƒ¼Tã‚’æ›´æ–°")
    return f"{update_count} ä»¶æ›´æ–°", 200


# ============================================================
#  2) ãƒãƒªãƒ¥ãƒ¼ï¼ˆç”»åƒç‰ˆï¼‰æŠ½å‡º
# ============================================================
def extract_value_from_pdf(pdf_bytes):
    global image_model
    if image_model is None:
        image_model = init_gemini()

    try:
        images = convert_from_bytes(pdf_bytes, dpi=200, first_page=1, last_page=10)

        prompt = """
        ã“ã®ç”»åƒã¯ä¼šç¤¾ã®çµ±åˆå ±å‘Šæ›¸ã®æœ€åˆã®æ•°ãƒšãƒ¼ã‚¸ã§ã™ã€‚
        ä¼šç¤¾ãŒè¨˜è¼‰ã—ã¦ã„ã‚‹ãƒãƒªãƒ¥ãƒ¼(Value)ã€ä¾¡å€¤è¦³ã€è¡Œå‹•æŒ‡é‡ã€è¡Œå‹•è¦ç¯„ãªã©ã®ã€Œä¸­èº«ã€ã‚’150æ–‡å­—ä»¥å†…ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

        ãƒ»ç¤¾å“¡ã«æ±‚ã‚ã‚‰ã‚Œã‚‹å§¿å‹¢ãƒ»è¡Œå‹•ã‚’å„ªå…ˆ
        ãƒ»èª¬æ˜ã¯ç¦æ­¢
        ãƒ»ãƒ©ãƒ™ãƒ«ï¼ˆãƒãƒªãƒ¥ãƒ¼ç­‰ï¼‰ã¯ä¸è¦
        ãƒ»å–å¾—ã§ããªã„å ´åˆã¯ã€Œå–å¾—å¤±æ•—ã€
        """

        response = image_model.generate_content([prompt, *images])
        result = response.text.strip()

        return result if result else "å–å¾—å¤±æ•—"

    except Exception as e:
        warnings.warn(f"Geminiç”»åƒå‡¦ç†å¤±æ•—: {e}")
        return "å–å¾—å¤±æ•—"


# ============================================================
#  update_ãƒãƒªãƒ¥ãƒ¼Gï¼ˆç”»åƒï¼‰
# ============================================================
def update_ãƒãƒªãƒ¥ãƒ¼G(worksheet):
    logging.info("ğŸ–¼ï¸ update_ãƒãƒªãƒ¥ãƒ¼G é–‹å§‹")

    df = get_as_dataframe(worksheet)
    df.fillna('', inplace=True)

    if 'ãƒãƒªãƒ¥ãƒ¼G' not in df.columns:
        df['ãƒãƒªãƒ¥ãƒ¼G'] = ''

    update_count = 0

    for idx, row in df.iterrows():
        url = row.get("URL", "")
        val_g = row.get("ãƒãƒªãƒ¥ãƒ¼G", "")
        company = row.get("ä¼šç¤¾å", "")

        if not url or val_g:
            continue

        if company in ["å¯¾è±¡å¤–", "å–å¾—å¤±æ•—", ""]:
            df.at[idx, "ãƒãƒªãƒ¥ãƒ¼G"] = "å¯¾è±¡å¤–"
            update_count += 1
            logging.info(f"â­ï¸ å¯¾è±¡å¤–ï¼ˆä¼šç¤¾åï¼‰: {url}")
            continue

        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            res = requests.get(url, headers=headers, timeout=20)

            if res.status_code == 200:
                extracted = extract_value_from_pdf(res.content)
                df.at[idx, "ãƒãƒªãƒ¥ãƒ¼G"] = extracted
                update_count += 1
                logging.info(f"ğŸ–¼ï¸ æŠ½å‡º(G): {url} â†’ {extracted}")

            else:
                df.at[idx, "ãƒãƒªãƒ¥ãƒ¼G"] = "å–å¾—å¤±æ•—"
                update_count += 1
                logging.warning(f"âš ï¸ DLå¤±æ•— {res.status_code}: {url}")

        except Exception as e:
            df.at[idx, "ãƒãƒªãƒ¥ãƒ¼G"] = "å–å¾—å¤±æ•—"
            update_count += 1
            logging.warning(f"âŒ ä¾‹å¤–ç™ºç”Ÿ {e}: {url}")

    df.replace([np.nan, np.inf, -np.inf], '', inplace=True)

    # Excelåˆ—åè¨ˆç®—
    def col_to_letter(index):
        letters = ""
        while index >= 0:
            index, rem = divmod(index, 26)
            letters = chr(65 + rem) + letters
            index -= 1
        return letters

    col_index = df.columns.get_loc("ãƒãƒªãƒ¥ãƒ¼G")
    col_letter = col_to_letter(col_index)

    worksheet.update(
        f"{col_letter}2:{col_letter}{len(df)+1}",
        [[v] for v in df["ãƒãƒªãƒ¥ãƒ¼G"].tolist()]
    )

    logging.info(f"ğŸ“ {update_count} ä»¶ã®ãƒãƒªãƒ¥ãƒ¼Gã‚’æ›´æ–°")
    return f"{update_count} ä»¶æ›´æ–°", 200


# ============================================================
#  ãƒãƒªãƒ¥ãƒ¼çµ±åˆå‡¦ç†
# ============================================================
def merge_values(value_t, value_g):
    """T/G ã‚’çµ±åˆã—ã¦1ã¤ã®ãƒãƒªãƒ¥ãƒ¼ã‚’ä½œæˆ"""

    def is_valid(v):
        return v and v not in ["å–å¾—å¤±æ•—", "å¯¾è±¡å¤–"]

    # ç‰‡æ–¹ã ã‘æœ‰åŠ¹ â†’ ãã‚Œã ã‘ã‚’æ¡ç”¨
    if is_valid(value_t) and not is_valid(value_g):
        return value_t

    if is_valid(value_g) and not is_valid(value_t):
        return value_g

    # ä¸¡æ–¹ç„¡åŠ¹
    if not is_valid(value_t) and not is_valid(value_g):
        return "å–å¾—å¤±æ•—"

    # ä¸¡æ–¹æœ‰åŠ¹ â†’ Gemini ã§çµ±åˆ
    global merge_model
    if merge_model is None:
        merge_model = init_merge_model()

    prompt = f"""
    æ¬¡ã®2ã¤ã®æŠ½å‡ºçµæœã‚’ã‚‚ã¨ã«ã€ä¼æ¥­ã®ã€Œãƒãƒªãƒ¥ãƒ¼ã€ã€Œä¾¡å€¤è¦³ã€ã€Œè¡Œå‹•æŒ‡é‡ã€ã«è©²å½“ã™ã‚‹å†…å®¹ã‚’
    200æ–‡å­—ä»¥å†…ã§çµ±åˆã—ã¦ãã ã•ã„ã€‚

    ---
    æŠ½å‡º1: {value_t}
    æŠ½å‡º2: {value_g}
    ---

    æ¡ä»¶:
    ãƒ»èª¬æ˜æ–‡ã‚„ãƒ©ãƒ™ãƒ«ã¯ä¸è¦ã€å†…å®¹ã ã‘ã‚’è¿”ã™
    ãƒ»ç¤¾å“¡ã«æ±‚ã‚ã‚‰ã‚Œã‚‹å§¿å‹¢ã‚„è¡Œå‹•ãŒä¼ã‚ã‚‹å†…å®¹ã‚’å„ªå…ˆ
    ãƒ»70æ–‡å­—æœªæº€ã®å ´åˆã¯ã€Œå–å¾—å¤±æ•—ã€ã¨è¿”ã™
    ãƒ»çµ±åˆã«å¤±æ•—ã—ãŸå ´åˆã‚‚ã€Œå–å¾—å¤±æ•—ã€ã¨è¿”ã™
    """

    try:
        res = merge_model.generate_content(prompt)
        result = res.text.strip()

        if not result or len(result) < 70:
            return "å–å¾—å¤±æ•—"

        return result

    except Exception as e:
        logging.warning(f"âŒ Geminiãƒãƒ¼ã‚¸å¤±æ•—: {e}")
        return "å–å¾—å¤±æ•—"


# ============================================================
#  update_ãƒãƒªãƒ¥ãƒ¼
# ============================================================
def update_ãƒãƒªãƒ¥ãƒ¼(worksheet):

    logging.info("ğŸ”„ update_ãƒãƒªãƒ¥ãƒ¼ é–‹å§‹")

    df = get_as_dataframe(worksheet)
    df.fillna('', inplace=True)

    # åˆ—ãŒãªã‘ã‚Œã°è¿½åŠ 
    if "ãƒãƒªãƒ¥ãƒ¼" not in df.columns:
        df["ãƒãƒªãƒ¥ãƒ¼"] = ""

    update_count = 0

    for idx, row in df.iterrows():
        current = row.get("ãƒãƒªãƒ¥ãƒ¼", "")
        company = row.get("ä¼šç¤¾å", "")

        # ã™ã§ã«å…¥åŠ›æ¸ˆã¿ãªã‚‰é£›ã°ã™
        if current:
            continue

        # å¯¾è±¡å¤–ä¼æ¥­
        if company == "å¯¾è±¡å¤–":
            df.at[idx, "ãƒãƒªãƒ¥ãƒ¼"] = "å¯¾è±¡å¤–"
            update_count += 1
            logging.info(f"â­ï¸ å¯¾è±¡å¤–ï¼ˆä¼šç¤¾åï¼‰: {row.get('URL', '')}")
            continue

        merged = merge_values(row.get("ãƒãƒªãƒ¥ãƒ¼T", ""), row.get("ãƒãƒªãƒ¥ãƒ¼G", ""))
        df.at[idx, "ãƒãƒªãƒ¥ãƒ¼"] = merged
        update_count += 1

        short = merged[:30] + ("â€¦" if len(merged) > 30 else "")
        logging.info(f"ğŸ“ {row.get('URL', '')} â†’ {short}")

    df.replace([np.nan, np.inf, -np.inf], "", inplace=True)

    # Excelåˆ—åå¤‰æ›ï¼ˆAAå¯¾å¿œï¼‰
    def col_to_letter(index):
        letters = ''
        while index >= 0:
            index, rem = divmod(index, 26)
            letters = chr(65 + rem) + letters
            index -= 1
        return letters

    col_index = df.columns.get_loc("ãƒãƒªãƒ¥ãƒ¼")
    col_letter = col_to_letter(col_index)

    worksheet.update(
        f"{col_letter}2:{col_letter}{len(df)+1}",
        [[v] for v in df["ãƒãƒªãƒ¥ãƒ¼"].tolist()]
    )

    logging.info(f"ğŸ“ update_ãƒãƒªãƒ¥ãƒ¼: {update_count} ä»¶ æ›´æ–°å®Œäº†")

    return f"{update_count} ä»¶æ›´æ–°", 200
