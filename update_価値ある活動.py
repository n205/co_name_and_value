import logging
import requests
import numpy as np
from io import BytesIO
from pypdf import PdfReader
from pdf2image import convert_from_bytes
import warnings
from gspread_dataframe import get_as_dataframe
import google.generativeai as genai
import os


# -------------------------------
# Gemini åˆæœŸåŒ–ï¼ˆå…±é€šï¼‰
# -------------------------------
def init_gemini():
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise RuntimeError("ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    genai.configure(api_key=api_key)
    return genai.GenerativeModel("gemini-2.5-flash")


text_model = None
image_model = None


# ============================================================
#  1) ãƒãƒªãƒ¥ãƒ¼ï¼ˆãƒ†ã‚­ã‚¹ãƒˆç‰ˆï¼‰æŠ½å‡º
# ============================================================
def extract_value_from_text(pdf_bytes):
    global text_model
    if text_model is None:
        text_model = init_gemini()

    try:
        reader = PdfReader(BytesIO(pdf_bytes))
        all_text = ""

        for i in range(min(10, len(reader.pages))):
            text = reader.pages[i].extract_text()
            if text:
                all_text += text + "\n"

        if not all_text.strip():
            return "å–å¾—å¤±æ•—"

        prompt = """
        ä»¥ä¸‹ã¯ä¼æ¥­ã®çµ±åˆå ±å‘Šæ›¸ã§ã™ã€‚
        ã“ã®ä¸­ã‹ã‚‰ä¼æ¥­ãŒæç¤ºã—ã¦ã„ã‚‹ã€Œãƒãƒªãƒ¥ãƒ¼ã€ã€Œè¡Œå‹•æŒ‡é‡ã€ã€Œä¾¡å€¤è¦³ã€ã€Œè¡Œå‹•è¦ç¯„ã€ã«è©²å½“ã™ã‚‹å†…å®¹ã‚’150æ–‡å­—ä»¥å†…ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚

        ãƒ»ç¤¾å“¡ãŒã©ã®ã‚ˆã†ãªè¡Œå‹•ã‚„å§¿å‹¢ã‚’æ±‚ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã‹ã‚’å„ªå…ˆ
        ãƒ»èª¬æ˜æ–‡ã€å‰ç½®ãã€ãƒ©ãƒ™ãƒ«ã¯ä¸è¦
        ãƒ»å†…å®¹ãã®ã‚‚ã®ã ã‘ã‚’è¿”ã™
        ãƒ»å–å¾—ã§ããªã„å ´åˆã¯ã€Œå–å¾—å¤±æ•—ã€ã¨ã ã‘è¿”ã™
        """

        response = text_model.generate_content([prompt, all_text])
        result = response.text.strip()

        return result if result else "å–å¾—å¤±æ•—"

    except Exception as e:
        warnings.warn(f"Geminiãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†å¤±æ•—: {e}")
        return "å–å¾—å¤±æ•—"


# ============================================================
#  update_ãƒãƒªãƒ¥ãƒ¼Tï¼ˆãƒ†ã‚­ã‚¹ãƒˆï¼‰
# ============================================================
def update_ãƒãƒªãƒ¥ãƒ¼T(worksheet):
    logging.info("ğŸ§­ update_ãƒãƒªãƒ¥ãƒ¼T é–‹å§‹")

    df = get_as_dataframe(worksheet)
    df.fillna('', inplace=True)

    if 'ãƒãƒªãƒ¥ãƒ¼T' not in df.columns:
        df['ãƒãƒªãƒ¥ãƒ¼T'] = ''

    update_count = 0

    for idx, row in df.iterrows():
        url = row.get("URL", "")
        val_t = row.get("ãƒãƒªãƒ¥ãƒ¼T", "")
        company = row.get("ä¼šç¤¾å", "")

        if not url or val_t:
            continue

        if company in ["å¯¾è±¡å¤–", "å–å¾—å¤±æ•—", ""]:
            df.at[idx, "ãƒãƒªãƒ¥ãƒ¼T"] = "å¯¾è±¡å¤–"
            update_count += 1
            logging.info(f"â­ï¸ å¯¾è±¡å¤–ï¼ˆä¼šç¤¾åï¼‰: {url}")
            continue

        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            res = requests.get(url, headers=headers, timeout=20)

            if res.status_code == 200:
                extracted = extract_value_from_text(res.content)
                df.at[idx, "ãƒãƒªãƒ¥ãƒ¼T"] = extracted
                update_count += 1
                logging.info(f"ğŸ“ æŠ½å‡º(T): {url} â†’ {extracted}")

            else:
                df.at[idx, "ãƒãƒªãƒ¥ãƒ¼T"] = "å–å¾—å¤±æ•—"
                update_count += 1
                logging.warning(f"âš ï¸ DLå¤±æ•— {res.status_code}: {url}")

        except Exception as e:
            df.at[idx, "ãƒãƒªãƒ¥ãƒ¼T"] = "å–å¾—å¤±æ•—"
            update_count += 1
            logging.warning(f"âŒ ä¾‹å¤–ç™ºç”Ÿ {e}: {url}")

    df.replace([np.nan, np.inf, -np.inf], '', inplace=True)

    # Excel åˆ—åå¤‰æ›
    def col_to_letter(index):
        letters = ""
        while index >= 0:
            index, rem = divmod(index, 26)
            letters = chr(65 + rem) + letters
            index -= 1
        return letters

    col_index = df.columns.get_loc("ãƒãƒªãƒ¥ãƒ¼T")
    col_letter = col_to_letter(col_index)

    worksheet.update(
        f"{col_letter}2:{col_letter}{len(df)+1}",
        [[v] for v in df["ãƒãƒªãƒ¥ãƒ¼T"].tolist()]
    )

    logging.info(f"ğŸ“ {update_count} ä»¶ã®ãƒãƒªãƒ¥ãƒ¼Tã‚’æ›´æ–°")
    return f"{update_count} ä»¶æ›´æ–°", 200


# ============================================================
#  2) ãƒãƒªãƒ¥ãƒ¼ï¼ˆç”»åƒç‰ˆï¼‰æŠ½å‡º
# ============================================================
def extract_value_from_pdf(pdf_bytes):
    global image_model
    if image_model is None:
        image_model = init_gemini()

    try:
        images = convert_from_bytes(pdf_bytes, dpi=200, first_page=1, last_page=10)

        prompt = """
        ã“ã®ç”»åƒã¯ä¼šç¤¾ã®çµ±åˆå ±å‘Šæ›¸ã®æœ€åˆã®æ•°ãƒšãƒ¼ã‚¸ã§ã™ã€‚
        ä¼šç¤¾ãŒè¨˜è¼‰ã—ã¦ã„ã‚‹ãƒãƒªãƒ¥ãƒ¼(Value)ã€ä¾¡å€¤è¦³ã€è¡Œå‹•æŒ‡é‡ã€è¡Œå‹•è¦ç¯„ãªã©ã®ã€Œä¸­èº«ã€ã‚’150æ–‡å­—ä»¥å†…ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

        ãƒ»ç¤¾å“¡ã«æ±‚ã‚ã‚‰ã‚Œã‚‹å§¿å‹¢ãƒ»è¡Œå‹•ã‚’å„ªå…ˆ
        ãƒ»èª¬æ˜ã‚„ãƒ©ãƒ™ãƒ«ï¼ˆãƒãƒªãƒ¥ãƒ¼ç­‰ï¼‰ã¯ä¸è¦
        ãƒ»å–å¾—ã§ããªã„å ´åˆã¯ã€Œå–å¾—å¤±æ•—ã€ã¨ã ã‘è¿”ã™
        """

        response = image_model.generate_content([prompt, *images])
        result = response.text.strip()

        return result if result else "å–å¾—å¤±æ•—"

    except Exception as e:
        warnings.warn(f"Geminiç”»åƒå‡¦ç†å¤±æ•—: {e}")
        return "å–å¾—å¤±æ•—"


# ============================================================
#  update_ãƒãƒªãƒ¥ãƒ¼Gï¼ˆç”»åƒï¼‰
# ============================================================
def update_ãƒãƒªãƒ¥ãƒ¼G(worksheet):
    logging.info("ğŸ–¼ï¸ update_ãƒãƒªãƒ¥ãƒ¼G é–‹å§‹")

    df = get_as_dataframe(worksheet)
    df.fillna('', inplace=True)

    if 'ãƒãƒªãƒ¥ãƒ¼G' not in df.columns:
        df['ãƒãƒªãƒ¥ãƒ¼G'] = ''

    update_count = 0

    for idx, row in df.iterrows():
        url = row.get("URL", "")
        val_g = row.get("ãƒãƒªãƒ¥ãƒ¼G", "")
        company = row.get("ä¼šç¤¾å", "")

        if not url or val_g:
            continue

        if company in ["å¯¾è±¡å¤–", "å–å¾—å¤±æ•—", ""]:
            df.at[idx, "ãƒãƒªãƒ¥ãƒ¼G"] = "å¯¾è±¡å¤–"
            update_count += 1
            logging.info(f"â­ï¸ å¯¾è±¡å¤–ï¼ˆä¼šç¤¾åï¼‰: {url}")
            continue

        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            res = requests.get(url, headers=headers, timeout=20)

            if res.status_code == 200:
                extracted = extract_value_from_pdf(res.content)
                df.at[idx, "ãƒãƒªãƒ¥ãƒ¼G"] = extracted
                update_count += 1
                logging.info(f"ğŸ–¼ï¸ æŠ½å‡º(G): {url} â†’ {extracted}")

            else:
                df.at[idx, "ãƒãƒªãƒ¥ãƒ¼G"] = "å–å¾—å¤±æ•—"
                update_count += 1
                logging.warning(f"âš ï¸ DLå¤±æ•— {res.status_code}: {url}")

        except Exception as e:
            df.at[idx, "ãƒãƒªãƒ¥ãƒ¼G"] = "å–å¾—å¤±æ•—"
            update_count += 1
            logging.warning(f"âŒ ä¾‹å¤–ç™ºç”Ÿ {e}: {url}")

    df.replace([np.nan, np.inf, -np.inf], '', inplace=True)

    # Excelåˆ—åè¨ˆç®—
    def col_to_letter(index):
        letters = ""
        while index >= 0:
            index, rem = divmod(index, 26)
            letters = chr(65 + rem) + letters
            index -= 1
        return letters

    col_index = df.columns.get_loc("ãƒãƒªãƒ¥ãƒ¼G")
    col_letter = col_to_letter(col_index)

    worksheet.update(
        f"{col_letter}2:{col_letter}{len(df)+1}",
        [[v] for v in df["ãƒãƒªãƒ¥ãƒ¼G"].tolist()]
    )

    logging.info(f"ğŸ“ {update_count} ä»¶ã®ãƒãƒªãƒ¥ãƒ¼Gã‚’æ›´æ–°")
    return f"{update_count} ä»¶æ›´æ–°", 200


# ============================================================
#  3) ãƒãƒªãƒ¥ãƒ¼çµ±åˆï¼ˆT + G â†’ ãƒãƒªãƒ¥ãƒ¼ï¼‰
# ============================================================

merge_model = None

def merge_values(value_t, value_g):
    """ãƒãƒªãƒ¥ãƒ¼T ã¨ ãƒãƒªãƒ¥ãƒ¼G ã‚’çµ±åˆã—ã¦æœ€çµ‚ãƒãƒªãƒ¥ãƒ¼ã‚’è¿”ã™"""
    global merge_model
    if merge_model is None:
        merge_model = init_gemini()

    def is_valid(val):
        return val and val not in ["å–å¾—å¤±æ•—", "å¯¾è±¡å¤–"]

    # ç‰‡æ–¹ã ã‘æœ‰åŠ¹ â†’ ãã®ã¾ã¾æ¡ç”¨
    if is_valid(value_t) and not is_valid(value_g):
        return value_t

    if is_valid(value_g) and not is_valid(value_t):
        return value_g

    # ä¸¡æ–¹æœ‰åŠ¹ â†’ Gemini ã§çµ±åˆ
    if is_valid(value_t) and is_valid(value_g):
        try:
            prompt = f"""
ä»¥ä¸‹ã¯ä¼æ¥­ã®çµ±åˆå ±å‘Šæ›¸ã‹ã‚‰æŠ½å‡ºã—ãŸ2ã¤ã®è¦ç´ ã§ã™ã€‚

- æŠ½å‡º1: {value_t}
- æŠ½å‡º2: {value_g}

ã“ã‚Œã‚‰ã‚’å…ƒã«ä¼æ¥­ã®ã€Œãƒãƒªãƒ¥ãƒ¼ã€ã€Œè¡Œå‹•æŒ‡é‡ã€ã€Œä¾¡å€¤è¦³ã€ã«ã‚ãŸã‚‹å†…å®¹ã‚’200æ–‡å­—ä»¥å†…ã§çµ±åˆã—ã¦ãã ã•ã„ã€‚
ãƒ»ãƒ©ãƒ™ãƒ«ã‚„èª¬æ˜æ–‡ã¯ç¦æ­¢ã€‚å†…å®¹ã®ã¿è¿”ã™
ãƒ»ç¤¾å“¡ãŒã©ã†è¡Œå‹•ã™ã¹ãã‹ãŒä¼ã‚ã‚‹å†…å®¹ã‚’å„ªå…ˆ
ãƒ»ã†ã¾ãçµ±åˆã§ããªã„å ´åˆã€Œå–å¾—å¤±æ•—ã€ã¨è¿”ã™
ãƒ»æ–‡å­—æ•°ãŒåˆè¨ˆ100æ–‡å­—æœªæº€ã«ãªã£ã¦ã—ã¾ã†å ´åˆã€Œå–å¾—å¤±æ•—ã€ã¨ã ã‘è¿”ã™
"""
            response = merge_model.generate_content(prompt)
            result = response.text.strip()

            if not result or len(result) < 70:
                return "å–å¾—å¤±æ•—"
            return result

        except Exception as e:
            logging.warning(f"âŒ Geminiãƒãƒ¼ã‚¸å¤±æ•—: {e}")
            return "å–å¾—å¤±æ•—"

    # ã©ã¡ã‚‰ã‚‚ç„¡åŠ¹
    return "å–å¾—å¤±æ•—"


# ------------------------------------------------------------
# update_ãƒãƒªãƒ¥ãƒ¼
# ------------------------------------------------------------
def update_ãƒãƒªãƒ¥ãƒ¼(worksheet):
    logging.info("ğŸ”„ update_ãƒãƒªãƒ¥ãƒ¼ é–‹å§‹")

    df = get_as_dataframe(worksheet)
    df.fillna("", inplace=True)

    if "ãƒãƒªãƒ¥ãƒ¼" not in df.columns:
        df["ãƒãƒªãƒ¥ãƒ¼"] = ""

    update_count = 0

    for idx, row in df.iterrows():
        val_final = row.get("ãƒãƒªãƒ¥ãƒ¼", "")
        company = row.get("ä¼šç¤¾å", "")
        url = row.get("URL", "")

        # æ—¢ã«å€¤ãŒå…¥ã£ã¦ã„ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—
        if val_final:
            continue

        # å¯¾è±¡å¤–ãªã‚‰ãã®ã¾ã¾
        if company == "å¯¾è±¡å¤–":
            df.at[idx, "ãƒãƒªãƒ¥ãƒ¼"] = "å¯¾è±¡å¤–"
            update_count += 1
            logging.info(f"â­ï¸ å¯¾è±¡å¤–ï¼ˆä¼šç¤¾åï¼‰: {url}")
            continue

        merged = merge_values(row.get("ãƒãƒªãƒ¥ãƒ¼T", ""), row.get("ãƒãƒªãƒ¥ãƒ¼G", ""))
        df.at[idx, "ãƒãƒªãƒ¥ãƒ¼"] = merged
        update_count += 1
        logging.info(f"ğŸ“ çµ±åˆ: {url} â†’ {merged[:30]}...")

    df.replace([np.nan, np.inf, -np.inf], "", inplace=True)

    # Excelåˆ—åè¨ˆç®—ï¼ˆæ—¢å­˜æ–¹å¼ï¼‰
    def col_to_letter(index):
        letters = ""
        while index >= 0:
            index, rem = divmod(index, 26)
            letters = chr(65 + rem) + letters
            index -= 1
        return letters

    col_index = df.columns.get_loc("ãƒãƒªãƒ¥ãƒ¼")
    col_letter = col_to_letter(col_index)

    worksheet.update(
        f"{col_letter}2:{col_letter}{len(df)+1}",
        [[v] for v in df["ãƒãƒªãƒ¥ãƒ¼"].tolist()],
    )

    logging.info(f"ğŸ“ {update_count} ä»¶ã®ãƒãƒªãƒ¥ãƒ¼ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
    return f"{update_count} ä»¶æ›´æ–°", 200
