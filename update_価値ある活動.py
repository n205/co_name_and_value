import logging
import requests
import numpy as np
from io import BytesIO
from pypdf import PdfReader
from pdf2image import convert_from_bytes
import warnings
from gspread_dataframe import get_as_dataframe
import google.generativeai as genai
import os


# -------------------------------
# Gemini åˆæœŸåŒ–ï¼ˆå…±é€šï¼‰
# -------------------------------
def init_gemini():
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise RuntimeError("ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    genai.configure(api_key=api_key)
    return genai.GenerativeModel("gemini-2.0-flash")


text_model = None
image_model = None


# ============================================================
#  1) ãƒãƒªãƒ¥ãƒ¼ï¼ˆãƒ†ã‚­ã‚¹ãƒˆç‰ˆï¼‰æŠ½å‡º
# ============================================================
def extract_value_from_text(pdf_bytes):
    global text_model
    if text_model is None:
        text_model = init_gemini()

    try:
        reader = PdfReader(BytesIO(pdf_bytes))
        all_text = ""

        for i in range(min(10, len(reader.pages))):
            text = reader.pages[i].extract_text()
            if text:
                all_text += text + "\n"

        if not all_text.strip():
            return "å–å¾—å¤±æ•—"

        prompt = """
        ä»¥ä¸‹ã¯ä¼æ¥­ã®çµ±åˆå ±å‘Šæ›¸ã§ã™ã€‚
        ã“ã®ä¸­ã‹ã‚‰ä¼æ¥­ãŒæç¤ºã—ã¦ã„ã‚‹ã€Œãƒãƒªãƒ¥ãƒ¼ã€ã€Œè¡Œå‹•æŒ‡é‡ã€ã€Œä¾¡å€¤è¦³ã€ã€Œè¡Œå‹•è¦ç¯„ã€ã«è©²å½“ã™ã‚‹å†…å®¹ã‚’150æ–‡å­—ä»¥å†…ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚

        ãƒ»ç¤¾å“¡ãŒã©ã®ã‚ˆã†ãªè¡Œå‹•ã‚„å§¿å‹¢ã‚’æ±‚ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã‹ã‚’å„ªå…ˆ
        ãƒ»èª¬æ˜æ–‡ã€å‰ç½®ãã€ãƒ©ãƒ™ãƒ«ã¯ç¦æ­¢
        ãƒ»å†…å®¹ãã®ã‚‚ã®ã ã‘ã‚’è¿”ã™
        ãƒ»å–å¾—ã§ããªã„å ´åˆã¯ã€Œå–å¾—å¤±æ•—ã€
        """

        response = text_model.generate_content([prompt, all_text])
        result = response.text.strip()

        return result if result else "å–å¾—å¤±æ•—"

    except Exception as e:
        warnings.warn(f"Geminiãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†å¤±æ•—: {e}")
        return "å–å¾—å¤±æ•—"


# ============================================================
#  update_ãƒãƒªãƒ¥ãƒ¼Tï¼ˆãƒ†ã‚­ã‚¹ãƒˆï¼‰
# ============================================================
def update_ãƒãƒªãƒ¥ãƒ¼T(worksheet):
    logging.info("ğŸ§­ update_ãƒãƒªãƒ¥ãƒ¼T é–‹å§‹")

    df = get_as_dataframe(worksheet)
    df.fillna('', inplace=True)

    if 'ãƒãƒªãƒ¥ãƒ¼T' not in df.columns:
        df['ãƒãƒªãƒ¥ãƒ¼T'] = ''

    update_count = 0

    for idx, row in df.iterrows():
        url = row.get("URL", "")
        val_t = row.get("ãƒãƒªãƒ¥ãƒ¼T", "")
        company = row.get("ä¼šç¤¾å", "")

        if not url or val_t:
            continue

        if company in ["å¯¾è±¡å¤–", "å–å¾—å¤±æ•—", ""]:
            df.at[idx, "ãƒãƒªãƒ¥ãƒ¼T"] = "å¯¾è±¡å¤–"
            update_count += 1
            logging.info(f"â­ï¸ å¯¾è±¡å¤–ï¼ˆä¼šç¤¾åï¼‰: {url}")
            continue

        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            res = requests.get(url, headers=headers, timeout=20)

            if res.status_code == 200:
                extracted = extract_value_from_text(res.content)
                df.at[idx, "ãƒãƒªãƒ¥ãƒ¼T"] = extracted
                update_count += 1
                logging.info(f"ğŸ“ æŠ½å‡º(T): {url} â†’ {extracted}")

            else:
                df.at[idx, "ãƒãƒªãƒ¥ãƒ¼T"] = "å–å¾—å¤±æ•—"
                update_count += 1
                logging.warning(f"âš ï¸ DLå¤±æ•— {res.status_code}: {url}")

        except Exception as e:
            df.at[idx, "ãƒãƒªãƒ¥ãƒ¼T"] = "å–å¾—å¤±æ•—"
            update_count += 1
            logging.warning(f"âŒ ä¾‹å¤–ç™ºç”Ÿ {e}: {url}")

    df.replace([np.nan, np.inf, -np.inf], '', inplace=True)

    # Excel åˆ—åå¤‰æ›
    def col_to_letter(index):
        letters = ""
        while index >= 0:
            index, rem = divmod(index, 26)
            letters = chr(65 + rem) + letters
            index -= 1
        return letters

    col_index = df.columns.get_loc("ãƒãƒªãƒ¥ãƒ¼T")
    col_letter = col_to_letter(col_index)

    worksheet.update(
        f"{col_letter}2:{col_letter}{len(df)+1}",
        [[v] for v in df["ãƒãƒªãƒ¥ãƒ¼T"].tolist()]
    )

    logging.info(f"ğŸ“ {update_count} ä»¶ã®ãƒãƒªãƒ¥ãƒ¼Tã‚’æ›´æ–°")
    return f"{update_count} ä»¶æ›´æ–°", 200


# ============================================================
#  2) ãƒãƒªãƒ¥ãƒ¼ï¼ˆç”»åƒç‰ˆï¼‰æŠ½å‡º
# ============================================================
def extract_value_from_pdf(pdf_bytes):
    global image_model
    if image_model is None:
        image_model = init_gemini()

    try:
        images = convert_from_bytes(pdf_bytes, dpi=200, first_page=1, last_page=10)

        prompt = """
        ã“ã®ç”»åƒã¯ä¼šç¤¾ã®çµ±åˆå ±å‘Šæ›¸ã®æœ€åˆã®æ•°ãƒšãƒ¼ã‚¸ã§ã™ã€‚
        ä¼šç¤¾ãŒè¨˜è¼‰ã—ã¦ã„ã‚‹ãƒãƒªãƒ¥ãƒ¼(Value)ã€ä¾¡å€¤è¦³ã€è¡Œå‹•æŒ‡é‡ã€è¡Œå‹•è¦ç¯„ãªã©ã®ã€Œä¸­èº«ã€ã‚’150æ–‡å­—ä»¥å†…ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

        ãƒ»ç¤¾å“¡ã«æ±‚ã‚ã‚‰ã‚Œã‚‹å§¿å‹¢ãƒ»è¡Œå‹•ã‚’å„ªå…ˆ
        ãƒ»èª¬æ˜ã¯ç¦æ­¢
        ãƒ»ãƒ©ãƒ™ãƒ«ï¼ˆãƒãƒªãƒ¥ãƒ¼ç­‰ï¼‰ã¯ä¸è¦
        ãƒ»å–å¾—ã§ããªã„å ´åˆã¯ã€Œå–å¾—å¤±æ•—ã€
        """

        response = image_model.generate_content([prompt, *images])
        result = response.text.strip()

        return result if result else "å–å¾—å¤±æ•—"

    except Exception as e:
        warnings.warn(f"Geminiç”»åƒå‡¦ç†å¤±æ•—: {e}")
        return "å–å¾—å¤±æ•—"


# ============================================================
#  update_ãƒãƒªãƒ¥ãƒ¼Gï¼ˆç”»åƒï¼‰
# ============================================================
def update_ãƒãƒªãƒ¥ãƒ¼G(worksheet):
    logging.info("ğŸ–¼ï¸ update_ãƒãƒªãƒ¥ãƒ¼G é–‹å§‹")

    df = get_as_dataframe(worksheet)
    df.fillna('', inplace=True)

    if 'ãƒãƒªãƒ¥ãƒ¼G' not in df.columns:
        df['ãƒãƒªãƒ¥ãƒ¼G'] = ''

    update_count = 0

    for idx, row in df.iterrows():
        url = row.get("URL", "")
        val_g = row.get("ãƒãƒªãƒ¥ãƒ¼G", "")
        company = row.get("ä¼šç¤¾å", "")

        if not url or val_g:
            continue

        if company in ["å¯¾è±¡å¤–", "å–å¾—å¤±æ•—", ""]:
            df.at[idx, "ãƒãƒªãƒ¥ãƒ¼G"] = "å¯¾è±¡å¤–"
            update_count += 1
            logging.info(f"â­ï¸ å¯¾è±¡å¤–ï¼ˆä¼šç¤¾åï¼‰: {url}")
            continue

        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            res = requests.get(url, headers=headers, timeout=20)

            if res.status_code == 200:
                extracted = extract_value_from_pdf(res.content)
                df.at[idx, "ãƒãƒªãƒ¥ãƒ¼G"] = extracted
                update_count += 1
                logging.info(f"ğŸ–¼ï¸ æŠ½å‡º(G): {url} â†’ {extracted}")

            else:
                df.at[idx, "ãƒãƒªãƒ¥ãƒ¼G"] = "å–å¾—å¤±æ•—"
                update_count += 1
                logging.warning(f"âš ï¸ DLå¤±æ•— {res.status_code}: {url}")

        except Exception as e:
            df.at[idx, "ãƒãƒªãƒ¥ãƒ¼G"] = "å–å¾—å¤±æ•—"
            update_count += 1
            logging.warning(f"âŒ ä¾‹å¤–ç™ºç”Ÿ {e}: {url}")

    df.replace([np.nan, np.inf, -np.inf], '', inplace=True)

    # Excelåˆ—åè¨ˆç®—
    def col_to_letter(index):
        letters = ""
        while index >= 0:
            index, rem = divmod(index, 26)
            letters = chr(65 + rem) + letters
            index -= 1
        return letters

    col_index = df.columns.get_loc("ãƒãƒªãƒ¥ãƒ¼G")
    col_letter = col_to_letter(col_index)

    worksheet.update(
        f"{col_letter}2:{col_letter}{len(df)+1}",
        [[v] for v in df["ãƒãƒªãƒ¥ãƒ¼G"].tolist()]
    )

    logging.info(f"ğŸ“ {update_count} ä»¶ã®ãƒãƒªãƒ¥ãƒ¼Gã‚’æ›´æ–°")
    return f"{update_count} ä»¶æ›´æ–°", 200
