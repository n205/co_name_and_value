import logging
import requests
import numpy as np
from datetime import datetime
from pypdf import PdfReader
from io import BytesIO
import warnings
from gspread_dataframe import get_as_dataframe

import google.generativeai as genai
import os


# --- Gemini åˆæœŸåŒ– ---
def init_gemini():
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise RuntimeError("ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    genai.configure(api_key=api_key)
    return genai.GenerativeModel("gemini-2.0-flash")


text_model = None


def extract_company_name_from_text(pdf_bytes):
    """PDF ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ä¼šç¤¾åã‚’ Gemini ã§æŠ½å‡ºã™ã‚‹"""
    global text_model

    try:
        if text_model is None:
            text_model = init_gemini()

        reader = PdfReader(BytesIO(pdf_bytes))
        all_text = ''

        # æœ€åˆã® 3 ãƒšãƒ¼ã‚¸ã®ã¿ä½¿ç”¨
        for i in range(min(3, len(reader.pages))):
            page = reader.pages[i]
            page_text = page.extract_text()
            if page_text:
                all_text += page_text + '\n'

        if not all_text.strip():
            return "å–å¾—å¤±æ•—"

        prompt = """
        ä»¥ä¸‹ã¯çµ±åˆå ±å‘Šæ›¸ã®æœ€åˆã®æ•°ãƒšãƒ¼ã‚¸ã§ã™ã€‚
        ã“ã®ä¸­ã‹ã‚‰ã€Œä¼šç¤¾åã€ã‚’ 1 è¡Œã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

        - ã€Œæ ªå¼ä¼šç¤¾â—‹â—‹ã€ã€Œâ—‹â—‹æ ªå¼ä¼šç¤¾ã€å½¢å¼ãŒå¤šã„
        - å‡ºåŠ›ã«ã¯æ³•äººæ ¼ï¼ˆæ ªå¼ä¼šç¤¾ç­‰ï¼‰ã‚’å«ã‚ãªã„
        - è£œè¶³ã€è¨˜å·ã€èª¬æ˜ã¯ä¸è¦
        - å–å¾—ã«å¤±æ•—ã—ãŸå ´åˆã¯ã€Œå–å¾—å¤±æ•—ã€ã¨è¿”ã™
        """

        response = text_model.generate_content([prompt, all_text])
        result = response.text.strip()

        return result if result else "å–å¾—å¤±æ•—"

    except Exception as e:
        logging.warning(f"Geminiãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†å¤±æ•—ï¼ˆä¼šç¤¾åTï¼‰: {e}")
        return "å–å¾—å¤±æ•—"


# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
def update_company_name_t(worksheet):
    logging.info("ğŸ¢ update_company_name_t é–‹å§‹")

    df = get_as_dataframe(worksheet)
    df.fillna('', inplace=True)
    update_count = 0

    for idx, row in df.iterrows():
        url = row['URL']
        name_t = row.get('ä¼šç¤¾åT', '')
        page_count = row['ãƒšãƒ¼ã‚¸æ•°']

        # URL ãªã— or ã™ã§ã«è¨˜å…¥æ¸ˆã¿ã¯ã‚¹ã‚­ãƒƒãƒ—
        if not url or name_t:
            continue

        # ãƒšãƒ¼ã‚¸æ•° 15 ä»¥ä¸‹ã¯å¯¾è±¡å¤–
        if isinstance(page_count, (int, float)) and page_count <= 15:
            df.at[idx, 'ä¼šç¤¾åT'] = 'å¯¾è±¡å¤–'
            update_count += 1
            logging.info(f"â­ï¸ ãƒšãƒ¼ã‚¸æ•°å°‘ â†’ å¯¾è±¡å¤–: {url}")
            continue

        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            response = requests.get(url, headers=headers, timeout=15)

            if response.status_code == 200:
                extracted = extract_company_name_from_text(response.content)
                df.at[idx, 'ä¼šç¤¾åT'] = extracted
                logging.info(f"ğŸ” ä¼šç¤¾åT: {url} â†’ {extracted}")
            else:
                df.at[idx, 'ä¼šç¤¾åT'] = 'å–å¾—å¤±æ•—'
                logging.info(f"âš ï¸ PDFå–å¾—å¤±æ•— â†’ å–å¾—å¤±æ•—: {url}")

        except Exception as e:
            df.at[idx, 'ä¼šç¤¾åT'] = 'å–å¾—å¤±æ•—'
            logging.warning(f"âŒ ã‚¨ãƒ©ãƒ¼ â†’ å–å¾—å¤±æ•—: {e} â†’ {url}")

        update_count += 1

    # NaN ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    df.replace([np.nan, np.inf, -np.inf], '', inplace=True)

    # åˆ—ä½ç½® â†’ Excel å½¢å¼ã¸
    col_index = df.columns.get_loc('ä¼šç¤¾åT')
    col_letter = chr(ord('A') + col_index)

    # ã‚·ãƒ¼ãƒˆæ›´æ–°
    if update_count > 0:
        worksheet.update(
            f"{col_letter}2:{col_letter}{len(df)+1}",
            [[value] for value in df['ä¼šç¤¾åT'].tolist()]
        )
        logging.info(f"ğŸ“„ {update_count} ä»¶ã®ä¼šç¤¾åTã‚’æ›´æ–°")
    else:
        logging.info("ğŸ” æ›´æ–°ãªã—")

    return f"{update_count} ä»¶ã®ä¼šç¤¾åTæ›´æ–°", 200
